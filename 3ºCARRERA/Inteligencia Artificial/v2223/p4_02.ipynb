{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Práctica 4 de IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Construcción de un clasificador en una base de datos real (5 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/german_credit_data.csv', sep=';')\n",
    "# Source: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
    "# This dataset classifies people described by a set of attributes as good or bad credit risks. Comes in two formats (one all numeric). Also comes with a cost matrix\n",
    "\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 'default'\n",
    "feature_names = list(df.columns)\n",
    "feature_names.remove(class_label)\n",
    "print(feature_names)\n",
    "X = df[feature_names].values\n",
    "y = df[class_label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estadísticos básicos de cada atributo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos codificados de forma numérica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/german_credit_data_numeric.csv', sep=';')\n",
    "class_label = 'Class'\n",
    "feature_names = list(df.columns)\n",
    "feature_names.remove(class_label)\n",
    "print(feature_names)\n",
    "X = df[feature_names].values\n",
    "y = df[class_label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogramas suavizados de cada atributo en cada clase. El color indica la clase (\"default\"/\"no default\"):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 21))\n",
    "n_cols_plot = 4\n",
    "n_rows_plot = int(len(feature_names) / n_cols_plot)\n",
    "for i,n in enumerate(feature_names):\n",
    "    plt.subplot(n_rows_plot, n_cols_plot, i+1)\n",
    "    aux = 'Density' if i%n_cols_plot == 0 else ''\n",
    "    df.groupby('Class')[n].plot(kind='kde', title='Hist. de '+n)\n",
    "    plt.ylabel(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo y chequeo de su calidad usando 5-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda entrena un modelo y lo evalúa en varias particiones training-test diferentes de los datos. El resultado es un score medio junto a su desviación estándar. El tipo de modelo (Naïve Bayes / árbol de decisión / knn/ regresión logística / red neuronal) y parámetros empleados deberán ser seleccionados para que dicho resultado sea el mejor posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# otros clasificadores (del notebook p4_01)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1) # DecisionTreeClassifier(max_depth=3)\n",
    "scores = cross_val_score(clf, X, y, cv=10) # 10-fold cross-validation\n",
    "print('Precisión en cada una de las particiones: ', scores)\n",
    "print('Estimación de la precisión por validación cruzada: {:.2f} +/- {:.2f}'.format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Responde aquí a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Haz una gráfica que muestre la dependencia de la precisión de un clasificador de vecinos próximos con el número de vecinos. Si es más conveniente, utiliza gráficas en escala logarítmica para alguno de los ejes (`semilogx`, `semilogy`, `loglog`).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Utilizando los conceptos de sub- y sobreajuste:\n",
    "    * Comenta los resultados cuando el número de vecinos es pequeño.\n",
    "\n",
    "\n",
    "\n",
    "    * Comenta los resultados cuando el número de vecinos es grande.\n",
    "\n",
    "\n",
    "\n",
    "    * Explica el significado del valor de la precisión cuando el número de vecinos toma el valor mayor posible.\n",
    "\n",
    "\n",
    "* ¿Cuál es la mejor precisión que se alcanza con k-nn y para qué k (valor de `n_neighbours`)?\n",
    "\n",
    "El mejor score conseguido es 0.76 +/- 0.04 con un 'k' de valor 13\n",
    "\n",
    "* ¿Cuál es la mejor precisión que se alcanza con un árbol de decisión y con qué profundidad máxima (valor de `max_depth`)? Para ello, haz una gráfica que muestre la dependencia de la precisión con la profundidad máxima del árbol. Comenta los resultados.\n",
    "\n",
    "El mejor score conseguido es 0.75 +/- 0.03 con un 'max_depth' de valor 5\n",
    "\n",
    "* ¿Cuál es la mejor precisión que se alcanza con una red neuronal con una sola capa oculta y con qué configuración (valor de `hidden_layer_sizes`)? Para ello, haz una gráfica que muestre la dependencia de la precisión con el número de nodos en la capa oculta. Comenta los resultados.\n",
    "\n",
    "El mejor score conseguido es 0.75 +/- 0.03 con un 'hidden_layer_sizes' de valor (100, 10,)\n",
    "\n",
    "* ¿Cuál es la mejor precisión que se alcanza con una red neuronal con varias capas ocultas y con qué configuración? Para ello, haz una gráfica que muestre la dependencia de la precisión con el número de capas ocultas, suponiendo constante el número de nodos en cada capa oculta. Comenta los resultados.\n",
    "\n",
    "\n",
    "\n",
    "* Resume los resultados y conclusiones del estudio realizado.\n",
    "\n",
    "**Además de gráficas, puede ser conveniente presentar los resultados en forma de tablas.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[POR HACER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ocasiones, en lugar de utilizar modelos más complejos, es más útil invertir más tiempo en el procesamiento de los datos para conseguir mejores resultados.\n",
    "\n",
    "En este apartado vas a investigar mecanismos para preparar los datos y obtener (en principio) mejores resultados: construcción y selección de atributos, preprocesamiento (detección de outliers, missing values, centrado y escalado).\n",
    "\n",
    "Razona por qué decides probar o ignorar alguno de estos métodos, y cómo cambian los resultados al aplicarlos (puedes crear tantas celdas como consideres oportunas).\n",
    "Usa tablas, gráficas y código, según sea necesario, para ilustrar tus observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluye aquí código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se determina el valor de los hiperparámetros?\n",
    "\n",
    "Para determinar el valor de los hiperparámetros de un modelo realizaremos una búsqueda en una rejilla. De entre los valores considerados seleccionaremos los que maximicen la estimación por validación cruzada (K = 10) de la tasa de acierto.\n",
    "\n",
    "Adapta el código que encontrarás en \n",
    "[https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py)\n",
    "a este problema. \n",
    "\n",
    "En los tutoriales\n",
    "[https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html](\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "hay información sobre cada uno de los hiper-parámetros. \n",
    "Puedes elegir el conjunto de hiperparametros en el que se realiza la optimización. \n",
    "Antes de elegir la rejilla de hiperparámetros, asegúrate de que entiendes su para asegurarte que tiene sentido la búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluye aquí código\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 30\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"pima.csv\", header=0, sep=',')\n",
    "df.head(5)\n",
    "nombres_atrs = list(df.columns)\n",
    "nombres_atrs.remove('class')\n",
    "X = df[nombres_atrs].values\n",
    "y = df['class'].values\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv)\n",
    "    clf.fit(X, y)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "    nested_score = cross_val_score(clf, X=X, y=y, cv=outer_cv)\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "score_difference = non_nested_scores - nested_scores\n",
    "\n",
    "print(\n",
    "    \"Average difference of {:6f} with std. dev. of {:6f}.\".format(\n",
    "        score_difference.mean(), score_difference.std()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "(non_nested_scores_line,) = plt.plot(non_nested_scores, color=\"r\")\n",
    "(nested_line,) = plt.plot(nested_scores, color=\"b\")\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend(\n",
    "    [non_nested_scores_line, nested_line],\n",
    "    [\"Non-Nested CV\", \"Nested CV\"],\n",
    "    bbox_to_anchor=(0, 0.4, 0.5, 0),\n",
    ")\n",
    "plt.title(\n",
    "    \"Non-Nested and Nested Cross Validation on Iris Dataset\",\n",
    "    x=0.5,\n",
    "    y=1.1,\n",
    "    fontsize=\"15\",\n",
    ")\n",
    "\n",
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend(\n",
    "    [difference_plot],\n",
    "    [\"Non-Nested CV - Nested CV Score\"],\n",
    "    bbox_to_anchor=(0, 1, 0.8, 0),\n",
    ")\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se estima el error de generalización?\n",
    "\n",
    "Estimaremos el error de generalización de cada clasificador usando *Nested Cross Validation*. \n",
    "\n",
    "\n",
    "Adapta el código que encontrarás en https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html para resolver este problema con una red neuronal. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluye aquí código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cuál es el mejor clasificador?\n",
    "\n",
    "* De acuerdo con los resultados de los anteriores apartados, indica cuál es el mejor clasificador encontrado.\n",
    "* ¿Cuáles son los valores de los hiperparámetros utilizados para configurar y entrenar tal  clasificador?\n",
    "\n",
    "\n",
    "* ¿cuáles son los valores de los parámetros del clasificador entrenado?\n",
    "\n",
    "\n",
    "* Proporciona una estimación del error de generalización por validación cruzada, así como de la incertidumbre de dicha estimación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones.\n",
    "Resume los resultados y conclusiones del estudio que has realizado.\n",
    "[POR HACER]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a30d898375753148e8fc7012ddaeb574b6d0ae01b90a80f9092b4d27bfa7765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
