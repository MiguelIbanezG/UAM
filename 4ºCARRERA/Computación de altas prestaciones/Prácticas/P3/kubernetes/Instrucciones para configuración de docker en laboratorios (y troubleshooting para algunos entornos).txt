Arrancar docker en los laboratorios docentes

Para poder usar Docker en los laboratorios y arrancar nuestro clúster de Kubernetes, antes de instalar y arrancar Kubernetes debemos ejecutar:

sudo /usr/local/bin/si2setuid.sh 3000000:100000 $USER

dockerd-rootless-setuptool.sh install

export DOCKER_HOST=unix:///run/user/$(id -u)/docker.sock

docker info

Instalar minikube en los laboratorios

Como no se puede realizar el comando install que aparece en las instrucciones, es necesario renombrar el archivo descargado a minikube y agregarlo el directorio en el que se encuentre al PATH mediante a un comando similar a export PATH=$PATH:$(pwd).

De igual modo, kubectl no estará en el PATH, por lo que es necesario prefijar todo comando kubectl con minikube:

kubectl => minikube kubectl

Alternativamente, se puede hacer un alias en BASH.

Arrancar minikube con docker rootless (laboratorios docentes)

Si todo ha ido correctamente, el último comando debería mostrarnos algunos valores de configuración de docker. A partir de este punto ya podemos seguir el tutorial de instalación de Kubernetes, y, tras descargarlo, arrancarlo con las siguientes instrucciones:

docker context use rootless

minikube start --driver=docker --container-runtime=containerd 

Construir imágenes en el entorno de minikube con docker

Para crear las imágenes de Docker usaremos docker build para construirlas, pero es necesario usar después minikube image load para cargarlas debido a que minikube image build no funciona correctamente con imágenes base que no están en repositorios públicos.

Exponer servicios con minikube sobre docker

Para listar los servicios se puede usar el comando: 

minikube service list

Para expornerlos a localhost hay que ejecutar:


minikube service -n <namespace_servicio> <nombre-servicio> &



Lanzar un programa PySpark de ejemplo desde el host

Se debe usar la misma versión de Python que en los workers, en este caso, Python3.10. 
Se debe instalar también pyspark (python3.10 -m pip install pyspark). 
Se debe usar la URL del master de spark usando la IP y puerto del comando que expone servicios anterior (spark://<ip>:<puerto>)
Se debe configurar spark.driver.host a la dirección IP del host (obtenible mediante ifconfig o ip addr) para que el driver se comunique correctamente con el cluster. Alternativamente, se puede lanzar el ejemplo en un Pod dentro del mismo namespace. Por ejemplo, ejecutando dentro del maestro:
kubectl exec <nombre del Pod maestro> -it -- pyspark --conf spark.driver.bindAddress=<IP maestro> --conf spark.driver.host=<IP maestro> --master=spark://<hostname o IP del maestro>:7077

Si el comando anterior funciona pero el programa de prueba no, puede deberse a las reglas de firewall que pone docker. Se pueden borrar todas las reglas de FW usando "sudo iptables -F" aunque se recomienda reiniciar posteriormente pare rehabilitar el firewall de tu ordenador.